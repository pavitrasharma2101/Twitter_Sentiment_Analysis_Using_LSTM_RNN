{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_sentiment_analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH51guXy8GjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkH977678gxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "from tensorflow.keras.layers import Conv1D, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.layers import MaxPooling1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skw3pkYP9jWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/twitter30k.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxf3R6VT9l2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df['twitts'].tolist()\n",
        "y = df['sentiment']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnNnFR7s-fTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = stopwords.words('english')\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyAvUITB-3j6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "for sent in X:\n",
        "    sent = re.sub(\"[^a-zA-Z]\", \" \", sent)\n",
        "    sent = sent.lower().split()\n",
        "    sent = [lemmatizer.lemmatize(word) for word in sent if word not in set(stop_words)]\n",
        "    sent = \" \".join(sent)\n",
        "    x_train.append(sent)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUnApZkyAsGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x_train)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up7vB_56BaSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1 "
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aVu8c3LBeHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_texts = tokenizer.texts_to_sequences(x_train)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owMeqCdAC55w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_list = []\n",
        "for l in x_train:\n",
        "    testing_list.append(len(l.split(' ')))\n",
        "max_sentence_length = max(testing_list)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOVGvuT0D2jG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_X = pad_sequences(encoded_texts, maxlen=max_sentence_length, padding='post', truncating='post')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKFbcxApEBCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(padded_X, y, test_size=0.15, random_state=42)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7_JCZlJFaRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_features = 300"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr6jLZRdGY-k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1093742f-7432-4425-f74d-42577e9bad4d"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_features, input_length=max_sentence_length))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(64, recurrent_activation='relu', recurrent_dropout=0.2, return_sequences=True))\n",
        "model.add(LSTM(32, recurrent_activation='relu', recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2STn4vEHHFHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te0-qB9JJKhc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "6d183de4-4207-4d11-fc32-d5f7b06d027f"
      },
      "source": [
        "hist = model.fit(X_train, y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, y_test))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "797/797 [==============================] - 313s 392ms/step - loss: 0.6261 - accuracy: 0.6263 - val_loss: 0.5519 - val_accuracy: 0.7187\n",
            "Epoch 2/10\n",
            "797/797 [==============================] - 314s 394ms/step - loss: 0.4980 - accuracy: 0.7666 - val_loss: 0.5499 - val_accuracy: 0.7240\n",
            "Epoch 3/10\n",
            "797/797 [==============================] - 312s 391ms/step - loss: 0.4248 - accuracy: 0.8144 - val_loss: 0.5823 - val_accuracy: 0.7169\n",
            "Epoch 4/10\n",
            "797/797 [==============================] - 310s 389ms/step - loss: 0.3917 - accuracy: 0.8418 - val_loss: 0.6107 - val_accuracy: 0.7156\n",
            "Epoch 5/10\n",
            "797/797 [==============================] - 314s 393ms/step - loss: 0.3678 - accuracy: 0.8517 - val_loss: 0.6195 - val_accuracy: 0.7180\n",
            "Epoch 6/10\n",
            "797/797 [==============================] - 311s 391ms/step - loss: 0.3474 - accuracy: 0.8647 - val_loss: 0.6436 - val_accuracy: 0.7142\n",
            "Epoch 7/10\n",
            "797/797 [==============================] - 312s 392ms/step - loss: 0.3388 - accuracy: 0.8684 - val_loss: 0.6410 - val_accuracy: 0.7164\n",
            "Epoch 8/10\n",
            "797/797 [==============================] - 310s 389ms/step - loss: 0.3218 - accuracy: 0.8772 - val_loss: 0.6405 - val_accuracy: 0.7151\n",
            "Epoch 9/10\n",
            "797/797 [==============================] - 311s 390ms/step - loss: 0.3107 - accuracy: 0.8822 - val_loss: 0.6860 - val_accuracy: 0.7122\n",
            "Epoch 10/10\n",
            "797/797 [==============================] - 313s 393ms/step - loss: 0.2950 - accuracy: 0.8911 - val_loss: 0.7192 - val_accuracy: 0.7098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azFG1wP3NUP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/gdrive/My Drive/twitter.h5')"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYzePUL3YE8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "lstm_model = load_model('/content/gdrive/My Drive/twitter.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEpHHNtJg8_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiments = ['negative', 'positive']"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnRVrCx5dO2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_preprocess(text):\n",
        "    encoded = tokenizer.texts_to_sequences(text)\n",
        "    padded = pad_sequences(encoded, maxlen=max_sentence_length, padding='post', truncating='post')\n",
        "    return padded"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w0cfIwadrA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet1 = ['i want to kill myself'] #neg sentiment 0\n",
        "tweet2 = ['thank you very much'] #pos sentiment 1\n",
        "txt1 = text_preprocess(tweet1)\n",
        "txt2 = text_preprocess(tweet2)\n",
        "output1 = sentiments[lstm_model.predict_classes(txt1)[0][0]]\n",
        "output2 = sentiments[lstm_model.predict_classes(txt2)[0][0]]"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSlLR3J-eHIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f910339a-45ca-492c-b8ce-47c4baf7c518"
      },
      "source": [
        "print(output1, output2)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z2SGz8zhqop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
